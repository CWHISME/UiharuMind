# 快捷功能

## 快捷键

* 截图(Alt+Shift+Z)
* 快捷询问(Alt+Shift+A)
* 剪切板历史(Alt+Shift+S)
* 翻译(Alt+Shift+Q)

## 快捷菜单

* 当复制文字或图片(如果格式支持)后，会在鼠标位置出现一个菜单，点击可进行快捷操作。
* 操作会自动检测当前运行模型，如果当前模型未手动加载，则会自动从已添加的远程模型中查找。

# 截图

* 当截图被修改后，菜单栏会出现一个切换回原始图片的按钮，点击可以在两者之间切换。
* 图片的快捷菜单中，涉及 AI 的操作会自动检测当前运行模型是否支持多模态，若不支持，则从已添加的远程模型中查找。

# 对话

* 右键点击对话列表中的一条对话，可以执行对该条对话的操作，包括删除、编辑等。
* 右键点击对话的头像，可以执行对该条对话的操作，包括删除、编辑等。

# AI 模型

## 本地模型

本地模型运行支持 GGUF 量化模型，在主界面右侧的模型页签中，可配置本地模型文件的主目录，目录中存在的本地模型会自动被查找并加载于列表中。

如果目录中存在模型文件，但是模型列表中没有显示，请检查本地本地执行引擎是否正确配置：

* 设置->本地引擎设置->选择本地执行引擎
* 如果本地执行引擎列表中不存在任何项目，说明当前还未下载任何运行时，可以点击右侧 “检查更新” 按钮进行更新，会从 Github 自动拉取最新的运行列表。选择合适的运行时，点击下载即可。

如果是第一次设置后，出现了其它错误提示，可以尝试重启软件。

在模型列表存在的模型都可以在聊天页面顶部的模型运行菜单中选择运行。

本地模型的运行底层依赖 llama.cpp，因此 llama.cpp 支持的这边理论上也支持：

| Backend | Target devices |
| --- | --- |
| [Metal](docs/build.md#metal-build) | Apple Silicon |
| [BLAS](docs/build.md#blas-build) | All |
| [BLIS](docs/backend/BLIS.md) | All |
| [SYCL](docs/backend/SYCL.md) | Intel and Nvidia GPU |
| [MUSA](docs/build.md#musa) | Moore Threads MTT GPU |
| [CUDA](docs/build.md#cuda) | Nvidia GPU |
| [HIP](docs/build.md#hip) | AMD GPU |
| [Vulkan](docs/build.md#vulkan) | GPU |
| [CANN](docs/build.md#cann) | Ascend NPU |

注意：本地模型的运行请确保本机有足够配置。

## 远程模型

在线模型即使用在线 API，在主界面右侧的模型页签中，点击 远程模型添加按钮即可添加。只要兼容 OpenAI 接口就可以支持。

# 其它

在 Mac 系统下，如果重新安装后提示需要辅助功能权限，但是实际上已经存在于允许列表，可以使用减号按钮去掉应用，然后重新打开应用后再启用辅助功能权限。